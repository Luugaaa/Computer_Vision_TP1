{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc00c4d9",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d8915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in ./.venv/lib/python3.13/site-packages (4.13.0.90)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.4.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.13/site-packages (3.10.8)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-image in ./.venv/lib/python3.13/site-packages (0.26.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.13/site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.11.4 in ./.venv/lib/python3.13/site-packages (from scikit-image) (1.17.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.13/site-packages (from scikit-image) (3.6.1)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in ./.venv/lib/python3.13/site-packages (from scikit-image) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./.venv/lib/python3.13/site-packages (from scikit-image) (2026.1.14)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in ./.venv/lib/python3.13/site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless numpy matplotlib tqdm scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df0ab3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.13/site-packages (0.24.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch) (2026.1.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (from torchvision) (2.4.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.13/site-packages (from torchvision) (12.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8a77f9",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "653ba3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31669b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 5\n"
     ]
    }
   ],
   "source": [
    "data_root_path = \"data/UCF-101\"\n",
    "\n",
    "CLASS_NAMES = sorted(os.listdir(data_root_path))\n",
    "if '.DS_Store' in CLASS_NAMES :\n",
    "    CLASS_NAMES.remove('.DS_Store')\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e59cd05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to extract frames from a video file\n",
    "def extract_frames_from_video(video_path, frame_rate=5):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return frames\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(fps / frame_rate)\n",
    "\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frames.append(frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "## Function to extract frame data for all videos in the dataset\n",
    "def extract_dataset_frames(data_root_path, frame_rate=5):\n",
    "    dataset_frames = {}\n",
    "    for class_name in tqdm(CLASS_NAMES, desc=\"Processing classes\"):\n",
    "        class_path = os.path.join(data_root_path, class_name)\n",
    "        video_files = [f for f in os.listdir(class_path) if f.endswith('.avi')]\n",
    "        dataset_frames[class_name] = []\n",
    "        for video_file in tqdm(video_files, desc=f\"Processing videos in {class_name}\", leave=False):\n",
    "            video_path = os.path.join(class_path, video_file)\n",
    "            frames = extract_frames_from_video(video_path, frame_rate)\n",
    "            dataset_frames[class_name].extend(frames)\n",
    "    return dataset_frames\n",
    "\n",
    "def split_dataset(dataset, train_ratio=0.8):\n",
    "    train_set = {}\n",
    "    test_set = {}\n",
    "    for class_name, items in dataset.items():\n",
    "        random.shuffle(items)\n",
    "        split_index = int(len(items) * train_ratio)\n",
    "        train_set[class_name] = items[:split_index]\n",
    "        test_set[class_name] = items[split_index:]\n",
    "    return train_set, test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d34c9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes: 100%|██████████| 5/5 [00:17<00:00,  3.52s/it]\n"
     ]
    }
   ],
   "source": [
    "frames_dataset = extract_dataset_frames(data_root_path, frame_rate=5)\n",
    "frames_dataset = split_dataset(frames_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e846e48f",
   "metadata": {},
   "source": [
    "## ResNet Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "749a2133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /Users/gaspardjuillet/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97.8M/97.8M [00:51<00:00, 2.00MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preprocess = models.ResNet50_Weights.DEFAULT.transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a3c1e4",
   "metadata": {},
   "source": [
    "## Nearest Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_hog_averages(hog_features_dataset):\n",
    "    class_hog_averages = {}\n",
    "    for class_name, features in hog_features_dataset.items():\n",
    "        feature_vectors = [fd for fd, hog_image in features]\n",
    "        average_fd = np.mean(feature_vectors, axis=0)\n",
    "        class_hog_averages[class_name] = average_fd\n",
    "    return class_hog_averages\n",
    "\n",
    "class_hog_averages = compute_class_hog_averages(hog_features_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c955352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
